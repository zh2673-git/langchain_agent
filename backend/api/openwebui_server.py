"""
OpenWebUIå…¼å®¹çš„APIæœåŠ¡å™¨
æä¾›OpenAIå…¼å®¹çš„APIæ¥å£ï¼Œå¯ä»¥ç›´æ¥ä¸OpenWebUIé›†æˆ

ç‰¹ç‚¹ï¼š
1. å®Œå…¨å…¼å®¹OpenAI APIæ ¼å¼
2. æ”¯æŒæµå¼å“åº”
3. æ”¯æŒå¤šç§Agentåˆ‡æ¢
4. ä¸ä¿®æ”¹åç«¯ä»£ç 
5. å¯ç›´æ¥ä¸OpenWebUIé›†æˆ
"""

import asyncio
import sys
import os
import json
import uuid
from pathlib import Path
from typing import Dict, Any, List, Optional, AsyncGenerator
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import logging

# åˆå§‹åŒ–logger
logger = logging.getLogger(__name__)

# å¯¼å…¥åç«¯API
from backend.api import AgentAPI
from backend.api.openwebui_config import router as config_router
from backend.api.agent_mode_api import router as agent_mode_router
from backend.api.openwebui_models import router as models_router
from backend.api.openwebui_model_provider import router as model_provider_router


# OpenAIå…¼å®¹çš„æ•°æ®æ¨¡å‹
class ChatMessage(BaseModel):
    role: str
    content: str


class ChatCompletionRequest(BaseModel):
    model: str
    messages: List[ChatMessage]
    stream: bool = False
    temperature: float = 0.7
    max_tokens: Optional[int] = None


class ChatCompletionResponse(BaseModel):
    id: str
    object: str = "chat.completion"
    created: int
    model: str
    choices: List[Dict[str, Any]]
    usage: Dict[str, int]


class ModelInfo(BaseModel):
    id: str
    object: str = "model"
    created: int
    owned_by: str = "langchain-agent"


class OpenWebUIServer:
    """OpenWebUIå…¼å®¹æœåŠ¡å™¨"""
    
    def __init__(self):
        self.api = AgentAPI()
        self.initialized = False
        self.sessions: Dict[str, str] = {}  # request_id -> session_id
        
        # æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨ - æ‰©å±•æ”¯æŒå·¥å…·ä¿¡æ¯å’Œåº•å±‚æ¨¡å‹é…ç½®
        self.models = {
            "langchain-chain": {
                "description": "Chain Agent - åŸºäºRunnableæ¥å£ç»„åˆ",
                "agent_type": "chain",
                "supports_tools": True,
                "available_models": ["qwen2.5:7b", "qwen2.5:14b", "llama3.1:8b", "mistral:7b"],
                "default_model": "qwen2.5:7b"
            },
            "langchain-agent": {
                "description": "Agent Agent - ä½¿ç”¨create_tool_calling_agent",
                "agent_type": "agent",
                "supports_tools": True,
                "available_models": ["qwen2.5:7b", "qwen2.5:14b", "llama3.1:8b", "mistral:7b"],
                "default_model": "qwen2.5:7b"
            },
            "langchain-langgraph": {
                "description": "LangGraph Agent - ä½¿ç”¨çŠ¶æ€å›¾å®ç°",
                "agent_type": "langgraph",
                "supports_tools": True,
                "available_models": ["qwen2.5:7b", "qwen2.5:14b", "llama3.1:8b", "mistral:7b"],
                "default_model": "qwen2.5:7b"
            }
        }
    
    async def initialize(self):
        """åˆå§‹åŒ–API"""
        if not self.initialized:
            success = await self.api.initialize()
            if success:
                self.initialized = True
                print("âœ… OpenWebUIæœåŠ¡å™¨åˆå§‹åŒ–æˆåŠŸ")
            else:
                print("âŒ OpenWebUIæœåŠ¡å™¨åˆå§‹åŒ–å¤±è´¥")
                raise Exception("Failed to initialize API")
    
    def get_agent_type_from_model(self, model: str) -> str:
        """ä»æ¨¡å‹åç§°è·å–Agentç±»å‹"""
        model_mapping = {
            "langchain-chain": "chain",
            "langchain-agent": "agent", 
            "langchain-langgraph": "langgraph"
        }
        return model_mapping.get(model, "chain")
    
    def get_session_id(self, request_id: str) -> str:
        """è·å–æˆ–åˆ›å»ºä¼šè¯ID"""
        if request_id not in self.sessions:
            self.sessions[request_id] = f"openwebui_{uuid.uuid4().hex[:8]}"
        return self.sessions[request_id]
    
    async def chat_completion(self, request: ChatCompletionRequest, request_id: str = None) -> Dict[str, Any]:
        """å¤„ç†èŠå¤©å®Œæˆè¯·æ±‚"""
        if not self.initialized:
            await self.initialize()
        
        # åˆ‡æ¢åˆ°å¯¹åº”çš„Agent
        agent_type = self.get_agent_type_from_model(request.model)
        self.api.set_current_agent(agent_type)
        
        # è·å–ä¼šè¯ID
        session_id = self.get_session_id(request_id or str(uuid.uuid4()))
        
        # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        user_message = None
        for msg in reversed(request.messages):
            if msg.role == "user":
                user_message = msg.content
                break
        
        if not user_message:
            raise HTTPException(status_code=400, detail="No user message found")
        
        # è°ƒç”¨åç«¯API
        response = await self.api.chat(
            message=user_message,
            session_id=session_id
        )

        # ç¡®ä¿responseæ˜¯å­—å…¸æ ¼å¼
        if isinstance(response, str):
            # å¦‚æœè¿”å›çš„æ˜¯å­—ç¬¦ä¸²ï¼ŒåŒ…è£…æˆå­—å…¸æ ¼å¼
            response = {
                "success": True,
                "content": response,
                "tool_calls": []
            }
        elif not isinstance(response, dict):
            # å¦‚æœä¸æ˜¯å­—å…¸ä¹Ÿä¸æ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            response = {
                "success": True,
                "content": str(response),
                "tool_calls": []
            }

        if not response.get("success"):
            raise HTTPException(status_code=500, detail=response.get("error", "Unknown error"))

        # æ„å»ºOpenAIå…¼å®¹å“åº”
        completion_id = f"chatcmpl-{uuid.uuid4().hex[:8]}"
        content = response.get("content", "")
        
        # æ·»åŠ å·¥å…·è°ƒç”¨ä¿¡æ¯
        tool_calls = response.get("tool_calls", [])
        if tool_calls:
            tool_info = "\n\nğŸ”§ å·¥å…·è°ƒç”¨:\n"
            for call in tool_calls:
                tool_info += f"- {call.get('tool', 'Unknown')}: {call.get('result', 'No result')}\n"
            content += tool_info
        
        return {
            "id": completion_id,
            "object": "chat.completion",
            "created": int(datetime.now().timestamp()),
            "model": request.model,
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": content
                },
                "finish_reason": "stop"
            }],
            "usage": {
                "prompt_tokens": len(user_message.split()),
                "completion_tokens": len(content.split()),
                "total_tokens": len(user_message.split()) + len(content.split())
            }
        }
    
    async def chat_completion_stream(self, request: ChatCompletionRequest, request_id: str = None) -> AsyncGenerator[str, None]:
        """å¤„ç†æµå¼èŠå¤©å®Œæˆè¯·æ±‚"""
        if not self.initialized:
            await self.initialize()
        
        # åˆ‡æ¢åˆ°å¯¹åº”çš„Agent
        agent_type = self.get_agent_type_from_model(request.model)
        self.api.set_current_agent(agent_type)
        
        # è·å–ä¼šè¯ID
        session_id = self.get_session_id(request_id or str(uuid.uuid4()))
        
        # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        user_message = None
        for msg in reversed(request.messages):
            if msg.role == "user":
                user_message = msg.content
                break
        
        if not user_message:
            raise HTTPException(status_code=400, detail="No user message found")
        
        completion_id = f"chatcmpl-{uuid.uuid4().hex[:8]}"
        
        try:
            # ä½¿ç”¨æµå¼API
            async for chunk in self.api.chat_stream(
                message=user_message,
                session_id=session_id
            ):
                # ç¡®ä¿chunkæ˜¯å­—å…¸æ ¼å¼
                if isinstance(chunk, str):
                    chunk = {
                        "success": True,
                        "content": chunk,
                        "done": False
                    }
                elif not isinstance(chunk, dict):
                    chunk = {
                        "success": True,
                        "content": str(chunk),
                        "done": False
                    }

                if chunk.get("success"):
                    content = chunk.get("content", "")
                    if content:
                        # æ„å»ºæµå¼å“åº”å—
                        chunk_data = {
                            "id": completion_id,
                            "object": "chat.completion.chunk",
                            "created": int(datetime.now().timestamp()),
                            "model": request.model,
                            "choices": [{
                                "index": 0,
                                "delta": {
                                    "content": content
                                },
                                "finish_reason": None
                            }]
                        }
                        yield f"data: {json.dumps(chunk_data)}\n\n"
                    
                    # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                    if chunk.get("done"):
                        # å‘é€ç»“æŸæ ‡è®°
                        final_chunk = {
                            "id": completion_id,
                            "object": "chat.completion.chunk",
                            "created": int(datetime.now().timestamp()),
                            "model": request.model,
                            "choices": [{
                                "index": 0,
                                "delta": {},
                                "finish_reason": "stop"
                            }]
                        }
                        yield f"data: {json.dumps(final_chunk)}\n\n"
                        yield "data: [DONE]\n\n"
                        break
        
        except Exception as e:
            # é”™è¯¯å¤„ç†
            error_chunk = {
                "id": completion_id,
                "object": "chat.completion.chunk",
                "created": int(datetime.now().timestamp()),
                "model": request.model,
                "choices": [{
                    "index": 0,
                    "delta": {
                        "content": f"âŒ é”™è¯¯: {str(e)}"
                    },
                    "finish_reason": "stop"
                }]
            }
            yield f"data: {json.dumps(error_chunk)}\n\n"
            yield "data: [DONE]\n\n"


# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="LangChain Agent OpenWebUI API",
    description="OpenWebUIå…¼å®¹çš„LangChain Agent APIæœåŠ¡å™¨",
    version="1.0.0"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆ›å»ºæœåŠ¡å™¨å®ä¾‹
server = OpenWebUIServer()

# æ·»åŠ é…ç½®è·¯ç”±
app.include_router(config_router)
app.include_router(agent_mode_router)
# app.include_router(models_router)  # ç§»é™¤å†²çªçš„è·¯ç”±
app.include_router(model_provider_router)


# Ollamaä»£ç†API
@app.get("/api/tags")
async def proxy_ollama_tags():
    """ä»£ç†Ollamaçš„æ¨¡å‹åˆ—è¡¨API"""
    try:
        import httpx
        async with httpx.AsyncClient() as client:
            response = await client.get("http://host.docker.internal:11434/api/tags", timeout=10)
            if response.status_code == 200:
                return response.json()
            else:
                # è¿”å›é»˜è®¤æ¨¡å‹åˆ—è¡¨
                return {
                    "models": [
                        {"name": "qwen2.5:7b", "size": 4000000000},
                        {"name": "qwen2.5:14b", "size": 8000000000},
                        {"name": "llama3.1:8b", "size": 5000000000},
                        {"name": "mistral:7b", "size": 4000000000}
                    ]
                }
    except Exception as e:
        logger.error(f"Failed to proxy Ollama tags: {e}")
        return {
            "models": [
                {"name": "qwen2.5:7b", "size": 4000000000},
                {"name": "qwen2.5:14b", "size": 8000000000},
                {"name": "llama3.1:8b", "size": 5000000000},
                {"name": "mistral:7b", "size": 4000000000}
            ]
        }


@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨äº‹ä»¶"""
    await server.initialize()


@app.get("/v1/models")
async def list_models():
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹ - Agentæ¨¡å¼å’Œæ¨¡å‹åˆ†ç¦»çš„ç»„åˆæ¨¡å‹"""
    try:
        # ä½¿ç”¨æ–°çš„æ¨¡å‹æä¾›è€…
        from backend.api.openwebui_model_provider import get_openwebui_models
        result = await get_openwebui_models()
        logger.info(f"Model provider returned {len(result.get('data', []))} models")
        return result
    except Exception as e:
        logger.error(f"Failed to get models from provider: {e}")
        logger.exception("Full exception details:")
        # é™çº§åˆ°æ—§çš„æ¨¡å‹åˆ—è¡¨
        models = []

        # è·å–å·¥å…·ä¿¡æ¯
        tools_info = []
        if server.api and hasattr(server.api, 'tool_service') and server.api.tool_service:
            try:
                tool_names = server.api.tool_service.list_tool_names()
                for tool_name in tool_names:
                    tool_info = server.api.tool_service.get_tool_info(tool_name)
                    if tool_info:
                        tools_info.append({
                            "name": tool_name,
                            "description": tool_info.get("description", ""),
                            "parameters": tool_info.get("parameters", {})
                        })
            except Exception as e:
                print(f"è·å–å·¥å…·ä¿¡æ¯å¤±è´¥: {e}")

        for model_id, model_config in server.models.items():
            model_data = {
                "id": model_id,
                "object": "model",
                "created": int(datetime.now().timestamp()),
                "owned_by": "langchain-agent",
                "description": model_config["description"],
                "agent_type": model_config["agent_type"],
                "supports_tools": model_config["supports_tools"],
                "available_models": model_config["available_models"],
                "default_model": model_config["default_model"]
            }

            # å¦‚æœæ”¯æŒå·¥å…·ï¼Œæ·»åŠ å·¥å…·ä¿¡æ¯
            if model_config["supports_tools"] and tools_info:
                model_data["tools"] = tools_info

            models.append(model_data)

        return {"object": "list", "data": models}


@app.post("/v1/models/{agent_type}/switch")
async def switch_model(agent_type: str, request: dict):
    """ä¸ºæŒ‡å®šAgentåˆ‡æ¢åº•å±‚æ¨¡å‹"""
    try:
        new_model = request.get("model")
        if not new_model:
            raise HTTPException(status_code=400, detail="Missing model parameter")

        # éªŒè¯agent_type
        agent_model_id = f"langchain-{agent_type}"
        if agent_model_id not in server.models:
            raise HTTPException(status_code=404, detail=f"Agent type {agent_type} not found")

        # éªŒè¯æ¨¡å‹æ˜¯å¦åœ¨å¯ç”¨åˆ—è¡¨ä¸­
        available_models = server.models[agent_model_id]["available_models"]
        if new_model not in available_models:
            raise HTTPException(
                status_code=400,
                detail=f"Model {new_model} not available for {agent_type}. Available: {available_models}"
            )

        # è°ƒç”¨åç«¯APIåˆ‡æ¢æ¨¡å‹
        success = await server.api.switch_agent_model(agent_type, new_model)

        if success:
            return {
                "success": True,
                "message": f"Successfully switched {agent_type} to model {new_model}",
                "agent_type": agent_type,
                "new_model": new_model
            }
        else:
            raise HTTPException(status_code=500, detail="Failed to switch model")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/v1/tools")
async def list_tools():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨å·¥å…·"""
    try:
        if not server.api or not hasattr(server.api, 'tool_service') or not server.api.tool_service:
            return {"tools": [], "message": "Tool service not available"}

        tool_names = server.api.tool_service.list_tool_names()
        tools = []

        for tool_name in tool_names:
            tool_info = server.api.tool_service.get_tool_info(tool_name)
            if tool_info:
                tools.append({
                    "name": tool_name,
                    "description": tool_info.get("description", ""),
                    "parameters": tool_info.get("parameters", {}),
                    "enabled": True
                })

        return {
            "tools": tools,
            "count": len(tools),
            "message": f"Found {len(tools)} available tools"
        }

    except Exception as e:
        return {
            "tools": [],
            "error": str(e),
            "message": "Failed to retrieve tools"
        }


@app.post("/v1/tools/execute")
async def execute_tool(request: dict):
    """æ‰§è¡Œå·¥å…·ï¼ˆä¾›OpenWebUIå·¥å…·è°ƒç”¨ï¼‰"""
    try:
        tool_name = request.get("tool_name")
        parameters = request.get("parameters", {})

        if not tool_name:
            raise HTTPException(status_code=400, detail="Missing tool_name parameter")

        if not server.api or not hasattr(server.api, 'tool_service') or not server.api.tool_service:
            raise HTTPException(status_code=500, detail="Tool service not available")

        # æ‰§è¡Œå·¥å…·
        result = await server.api.tool_service.execute_tool(tool_name, **parameters)

        return {
            "success": True,
            "tool_name": tool_name,
            "result": result.get("result", ""),
            "message": "Tool executed successfully"
        }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Tool execution failed: {str(e)}")


@app.get("/v1/tools/openwebui")
async def get_openwebui_tools():
    """è·å–OpenWebUIæ ¼å¼çš„å·¥å…·"""
    try:
        if not server.api or not hasattr(server.api, 'tool_service') or not server.api.tool_service:
            return {"tools": {}, "message": "Tool service not available"}

        # è·å–OpenWebUIæ ¼å¼çš„å·¥å…·
        openwebui_tools = server.api.tool_service.get_openwebui_tools()

        return {
            "tools": openwebui_tools,
            "count": len(openwebui_tools),
            "message": f"Found {len(openwebui_tools)} OpenWebUI tools"
        }

    except Exception as e:
        return {
            "tools": {},
            "error": str(e),
            "message": "Failed to retrieve OpenWebUI tools"
        }


@app.post("/v1/chat/completions")
async def chat_completions(request: ChatCompletionRequest, http_request: Request):
    """èŠå¤©å®ŒæˆAPI"""
    request_id = http_request.headers.get("x-request-id", str(uuid.uuid4()))

    # ä¸´æ—¶ä¿®å¤ï¼šå¼ºåˆ¶æ‰€æœ‰è¯·æ±‚ä½¿ç”¨éæµå¼å“åº”ä»¥å…¼å®¹OpenWebUI
    # OpenWebUIå‘é€æµå¼è¯·æ±‚ä½†æœŸæœ›JSONå“åº”ï¼Œè¿™æ˜¯ä¸€ä¸ªå…¼å®¹æ€§é—®é¢˜

    # å¼ºåˆ¶è®¾ç½®ä¸ºéæµå¼
    request.stream = False

    # éæµå¼å“åº”
    response = await server.chat_completion(request, request_id)
    return JSONResponse(
        content=response,
        headers={
            "Content-Type": "application/json",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
            "Access-Control-Allow-Headers": "Content-Type, Authorization"
        }
    )


@app.get("/")
async def root():
    """æ ¹è·¯å¾„å¤„ç†"""
    return {
        "message": "LangChain Agent OpenWebUI API Server",
        "version": "1.0.0",
        "docs": "/docs",
        "health": "/health",
        "models": "/v1/models",
        "chat": "/v1/chat/completions"
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "initialized": server.initialized,
        "models": list(server.models.keys()),
        "timestamp": datetime.now().isoformat()
    }


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨OpenWebUIå…¼å®¹æœåŠ¡å™¨...")
    print("ğŸ“± APIåœ°å€: http://localhost:8000")
    print("ğŸ“š APIæ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸ”§ æ”¯æŒçš„æ¨¡å‹:")
    for model_id, description in server.models.items():
        print(f"   - {model_id}: {description}")
    print("\nğŸ’¡ OpenWebUIé…ç½®:")
    print("   1. åœ¨OpenWebUIä¸­æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹")
    print("   2. API Base URL: http://localhost:8000/v1")
    print("   3. API Key: ä»»æ„å€¼ï¼ˆä¸éªŒè¯ï¼‰")
    print("   4. æ¨¡å‹åç§°: langchain-chain, langchain-agent, langchain-langgraph")
    
    uvicorn.run(
        "openwebui_server:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        log_level="info"
    )


if __name__ == "__main__":
    main()
